from __future__ import annotations

import os
import discord
import asyncio
import config
import re

from discord.ext import commands
from asgiref.sync import sync_to_async
from typing import TYPE_CHECKING
from utils.logging import log, Ansi

import g4f.debug
from g4f.client import Client
from g4f.stubs import ChatCompletion
from g4f.Provider import Blackbox

g4f.debug.logging = True

if TYPE_CHECKING:
    from main import Bot

class AiChat(commands.Cog):
    def __init__(self, bot: Bot) -> None:
        self.bot = bot
        self.chatBot = Client(provider=Blackbox)
        self.chatModel = config.MODEL
        self.conversation_history = []
        config_dir = os.path.abspath(f"{__file__}/../../../")
        prompt_path = os.path.join(config_dir, "prompt.txt")
        with open(prompt_path, "r", encoding="utf-8") as f:
            self.starting_prompt = f.read()

        self.message_queue = asyncio.Queue()
        self.bot.loop.create_task(self.process_messages())

    async def process_messages(self):
        while True:
            while not self.message_queue.empty():
                ctx, user_message = await self.message_queue.get()
                async with ctx.channel.typing():
                    try:
                        await self.send_message(ctx, user_message)
                    except Exception as e:
                        log(f"error while processing message: {e}", Ansi.RED)
                    finally:
                        self.message_queue.task_done()

            await asyncio.sleep(1)

    @commands.command(name="chat", description="chat with kselon!")
    async def chat(self, ctx: commands.Context, *, user_message: str) -> None:
        """chat with kselon!
        usages: `!chat hello kselon`
        """
        await ctx.defer()
        await self.message_queue.put((ctx, user_message))

    @commands.command(name="resetai", description="resets the ai's brain")
    async def reset_chat(self, ctx: commands.Context) -> None:
        """resets the ai's brain"""
        await ctx.defer()
        self.conversation_history = []
        await self.send_start_prompt()
        await ctx.send("DONE :rofl: :rofl: :rofl: :rofl:")

    async def send_message(self, ctx: commands.Context, user_message: str):
        author = ctx.author
        try:
            user_name_message = f'{author.name}: {user_message}'
            response = await self.handle_response(user_name_message)
            response_content = f'> {user_name_message} \n{response}'
            await self.send_split_message(response_content, ctx)
        except Exception as e:
            log(f"error while sending: {e}", Ansi.YELLOW)
    
    async def handle_response(self, user_message: str) -> str:
        self.conversation_history.append({'role': 'user', 'content': user_message})
        if len(self.conversation_history) > 26:
            del self.conversation_history[4:6]
        
        async_create = sync_to_async(self.chatBot.chat.completions.create, thread_sensitive=True)
        response: ChatCompletion = await async_create(model=self.chatModel, messages=self.conversation_history)

        bot_response = response.choices[0].message.content

        # NOTE: lmao
        bot_response = re.sub(r"(?i)generated by blackbox\.ai,? try unlimited chat https://www\.blackbox\.ai/?", "", bot_response).strip()

        self.conversation_history.append({'role': 'assistant', 'content': bot_response})

        return bot_response

    async def send_start_prompt(self):
        if not config.use_start_prompt:
            log('use start prompt is false, skipping start prompt.', Ansi.YELLOW)
            return
        
        try:
            if self.starting_prompt and config.starting_prompt_id:
                channel = self.bot.get_channel(int(config.starting_prompt_id))
                log(f"starting ai system prompt with size {len(self.starting_prompt)}", Ansi.CYAN)

                response = await self.handle_response(self.starting_prompt)

                if channel is not None:
                    await channel.send(response)

                if config.DEBUG:
                    log(f"ai response: {response}", Ansi.GREEN)

            else:
                log("no starting prompt or channel selected; skipping prompt.", Ansi.YELLOW)
        except Exception as e:
            log(f"error while sending system prompt: {e}", Ansi.RED)

    async def send_split_message(self, response: str, ctx: commands.Context, has_followed_up=False):
        char_limit = 1900
        if len(response) > char_limit:
            is_code_block = False
            parts = response.split("```")

            for part in parts:
                chunks = [part[j:j+char_limit] for j in range(0, len(part), char_limit)]
                for chunk in chunks:
                    content = f"```{chunk}```" if is_code_block else chunk
                    if has_followed_up:
                        await ctx.channel.send(content)
                    else:
                        await ctx.send(content)
                        has_followed_up = True
                is_code_block = not is_code_block
        else:
            if has_followed_up:
                await ctx.channel.send(response)
            else:
                await ctx.send(response)
                has_followed_up = True
                
        return has_followed_up

async def setup(bot: Bot):
    await bot.add_cog(AiChat(bot))